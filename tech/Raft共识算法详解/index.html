<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Ganymede"><meta property="og:type" content="article"><meta property="og:image" content="https://dukezys.github.io/img/02s.jpg"><meta property="twitter:image" content="https://dukezys.github.io/img/02s.jpg"><meta name=title content="Raft共识算法详解"><meta property="og:title" content="Raft共识算法详解"><meta property="twitter:title" content="Raft共识算法详解"><meta name=description content="Raft共识算法详解"><meta property="og:description" content="Raft共识算法详解"><meta property="twitter:description" content="Raft共识算法详解"><meta property="twitter:card" content="summary"><meta name=keyword content="Duke, DukeSaika, Ganymede-, Ganymede, Blog, Duke的博客, 博客, 个人网站, 互联网, Web, .NET, Go, 分布式, Kubernetes, 微服务, Microservice"><link rel="shortcut icon" href=/img/favicon.ico><title>Raft共识算法详解-Duke's Blog</title><link rel=canonical href=/tech/Raft%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/ style=color:#000>Ganymede</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/ style=color:#000>Home</a></li><li><a href=/categories/tech style=color:#000>tech</a></li><li><a href=/top/books/ style=color:#000>BOOKS</a></li><li><a href=/top/about/ style=color:#000>ABOUT</a></li><li><a href=/search style=color:#000><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/02s.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/distributed-system title="Distributed System">Distributed System</a>
<a class=tag href=/tags/go title=Go>Go</a></div><h1>Raft共识算法详解</h1><h2 class=subheading></h2><span class=meta>Posted by
 Duke
on
Thursday, May 5, 2022</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><blockquote><p>本文主要参考自论文 <strong><a href=https://www.usenix.org/conference/atc14/technical-sessions/presentation/ongaro>In Search of an Understandable Consensus Algorithm</a>，结合MIT6.824的课程与实现Lab中的心得，尽量做到方便阅读和易于理解。由于水平有限，如果有遗漏或错误，欢迎指出或查阅原文。</strong></p></blockquote><h1 id=1-引言>1. 引言</h1><p>在Raft被提出之前的十年里，Leslie Lamport的Paxos协议作为一个最主要的共识算法被广泛使用，许多其他的共识算法也都是基于Paxos进行改良的。</p><p>然而，Paxos协议有几个严重的缺点：</p><ol><li><strong>非常难以理解</strong>：Paxos（包括multi-Paxos）的完整解释是十分模糊的，包括关于单决议二阶段的解释以及多决议组合的解释。</li><li><strong>Paxos没有提供一个很好的基础来构造实际的系统</strong>：对于Multi-Paxos来说，还没有一个广泛的共识。Lamport的描述大多是针对于Basic Paxos，但对于Multi-Paxos有很多细节是缺失的，导致有很多针对于Multi-Paxos不同的实现，但每一个都与Lamport的基本构想有区别。</li><li><strong>Paxos的理论系统架构非常糟糕</strong>：因为多决议是靠单决议组合而成的，独立选择多个 Log entry 然后合并成一个顺序 Log 的方式增加了复杂性。相反， 围绕单个 Log 构建系统会更加简单和高效，新的 entry 以严格方式顺序追加到这个 Log 文件。</li><li><strong>Paxos的核心是一个对称的点对点（symmetric peer-to-peer）模型，而不是强领导者模型</strong>：在简单的系统中，例如只需要做单个决议（decision）时是适用的。但如果需要做出一系列的决议，更简单和方便的做法是使用强领导者模型，选出Leader然后由Leader协调这些决议。</li></ol><p>基于以上原因，实际的系统与Paxos相似的地方不多。每种实现开始都是以Paxos为基础，然后在过程中发现了实现的困难，然后开发出了一个截然不同的架构。</p><h1 id=2-raft设计目标>2. Raft设计目标</h1><p>在设计Raft的过程中，最重要的目标就是确保Raft的<strong>可理解性</strong>。为了确保可理解性，使用了以下两种方法简化设计：</p><ol><li><strong>问题分解</strong>：尽可能将问题分解为独立的可解决、可解释和可理解的模块。例如，将领导者选举、日志复制、安全性、成员变更拆分开来。</li><li><strong>简化状态空间</strong>：通过减少需要考虑的状态数量，使系统更加清晰并消除存在的不确定性。具体来说，日志是连续的，并且避免了日志不一致的情况出现。</li></ol><p>与此同时，相比于其他的分布式算法，Raft也有一些新的特性：</p><ul><li><strong>强领导者模式</strong>：使用了比其他共识算法更强的领导者模型。例如， Log entries 只会从领导者向其他节点同步，简化了日志复制管理。</li><li><strong>领导者选举</strong>：在Raft中主要使用了一个随机的计时器来控制选举，比如Follower和Candidate的超时时间都是随机的，可以避免选举时的分裂问题。</li><li><strong>成员变更</strong>：采用了联合共识（joint consensus）的机制，在集群配置变更（新增/删除节点）时，使得集群可以正常工作。</li></ul><p>和Paxos或其他共识算法相比，优点有：</p><ul><li>更简单、更易理解</li><li>算法足够完整，易于工业界实现（已经有几种开源实现并在一些公司落地，例如etcd，Hashicorp Raft）</li><li>安全性有规范化描述并经过了证明</li><li>效率与其他算法相当</li></ul><h1 id=3-raft一致性算法>3. Raft一致性算法</h1><h2 id=31-基本名词和概念>3.1 基本名词和概念</h2><h3 id=311-复制状态机>3.1.1 复制状态机</h3><p><strong>复制状态机（replicated state machine）</strong> 是一种被广泛应用于解决分布式系统中容错（fault tolerance）问题的方法。在这种系统中，每个节点上的状态机拥有相同状态的副本，即使一些节点挂掉了，系统整体仍然能继续工作。</p><p>复制状态机通常通过如下图所示的<strong>复制式日志（replicated log）</strong> 来实现。共识算法管理着一个包含客户端发来的指令的复制式日志。状态机以完全相同的顺序执行日志中的命令，从而每台机器可以产生相同的结果。</p><p><img src=/img/220505Raft/Untitled.png alt=Untitled></p><ol><li>某个节点上的<strong>共识模块</strong>从客户端接收命令（command），然后写入本地Log 中，同时与其他节点上的共识模块通信，将Log复制到其他节点中，这样即使某些机器挂掉，最终每个节点中的Log中的命令顺序也是相同的。</li><li>每个 节点上的Log 都以相同的顺序保存了相同的命令，并且状态机能产生决定性的结果，因此最终每个状态机计算得到的是相同的状态和结果。</li><li>命令成功复制到其他节点之后，每个节点的状态机会按顺序处理这些命令，然后将结果返回给客 户端。从客户端的角度来看，这些节点就是一个高度可靠的状态机。</li></ol><p>在Raft的每个节点中，也是通过类似的复制状态机来实现日志复制以及存储的。</p><h3 id=312-角色>3.1.2 角色</h3><p>在任意时刻，每个节点都是Leader、Follower、Candidate三种角色中的一种：</p><ul><li><strong>Leader</strong>：正常情况下，每个集群只有一个Leader。负责处理客户端的写请求、日志复制、向Follower定期发送心跳信息。也就是说，数据是从 Leader向其他节点单向流动的。</li><li><strong>Candidate</strong>：Candidate节点向其他节点发送请求投票的RPC消息，如果赢得了大多数选票，就成为Leader。</li><li><strong>Follower</strong>：Follower是被动的，正常情况下不会主动发出请求；当超过一定时间没有收到来自Leader的心跳信息，就会time out，成为Candidate。</li></ul><p><img src=/img/220505Raft/Untitled%201.png alt=Untitled></p><p>上图是对应的状态机，可以看出节点状态变更的条件和方向，具体会在下面3.2选举中阐述。</p><h3 id=313-任期term>3.1.3 任期（Term）</h3><p>Raft将时间划分为长度不固定的任期，用连续的整数表示。</p><ol><li>每个任期都是从选举开始的，会有一个或多个 Candidate 都试图成为 Leader。也就是说，在一个 Follower变成 Candidate时，或 Candidate开始新一轮选举时，当前节点的任期 + 1。</li><li>一个 Candidate 赢得选举后，就会成为该任期内的 Leader；有时选举会失败（投票产生分裂，split vote），导致任期内没有 Leader，这种情况下，Candidate会再次超时，进行下一轮选举。</li><li>Raft 保证了在任意一个任期内，最多只会有一个 Leader。</li></ol><p>例如在下图中，在Term为3的时候，没有 Leader被选出来，那么就进行下一轮选举，Term + 1。</p><p><img src=/img/220505Raft/Untitled%202.png alt=Untitled></p><p>Raft 中，任期充当了<strong>逻辑时钟</strong>的作用，用来让各节点<strong>检测过期信息</strong>，例如过期的 Leader和 Candidate。每个节点都记录了当前任期编号 <strong>currentTerm</strong>，这个编号随着时间（选举轮数）单调递增。节点之间通信时，会带上它们的 currentTerm 信息；</p><ul><li>如果一个节点发现自己的 currentTerm 小于其他节点的，要立即更新自己的currentTerm。</li><li>如果一个 Candidate 或 Leader 发现自己的任期过期了，要切换到 Follower 状态。</li><li>如果一个节点接收到了比自己的任期编号小的请求，会拒绝这个请求。</li></ul><h3 id=314-角色的状态>3.1.4 角色的状态</h3><p><strong>在所有节点中持久状态</strong></p><p>处理客户端请求时，需要<strong>先更新这些持久状态（存储在稳定介质上），再响应请求</strong></p><ul><li><code>currentTerm</code>：节点已知的最近的任期编号（开始是0，单调递增）</li><li><code>votedFor</code>：在当前任期内投票给了哪个Candidate</li><li><code>log[]</code>：由Log entry组成，每个entry包含了一个 command（在状态机中使用）和收到entry时的term（索引从1开始）。</li></ul><p><strong>在所有节点中非持久状态</strong></p><ul><li><code>commitIndex</code>：最后提交（Committed）entry的index。</li><li><code>lastApplied</code>：最后apply到状态机里的entry的index。</li></ul><p><strong>在 Leader中非持久状态（在选举后重新初始化）</strong></p><p>在 Leader中，保存以下两个数组，为每个节点分别维护Log index：</p><ul><li><code>nextIndex[]</code>：对于每个节点，下一次发送Log entry时候的index。</li><li><code>matchIndex[]</code>：对于每个节点，已知的最后成功复制过去的entry的index。</li></ul><h3 id=315-节点间通信>3.1.5 节点间通信</h3><p>在Raft中选举和日志复制过程中，主要有两种RPC：AppendEntries RPC、RequestVote PRC（InstallSnapshot RPC会在日志压缩部分提到）。</p><ul><li><code>AppendEntries RPC</code>：由Leader发起，用来复制Log，也会被用来当作心跳消息。</li><li><code>RequestVote RPC</code>：由候选人发出，请求其他节点为自己投票。</li></ul><h3 id=316-raft特性>3.1.6 Raft特性</h3><p>Raft在所有时间内都可以保证以下特性：</p><ol><li><strong>Election Safety</strong>：在一个任期内最多只有一个Leader被选出来</li><li><strong>Leader Append-Only</strong>：Leader永远不覆盖或删除Log entry，只会追加新的entry</li><li><strong>Log Matching</strong>：如果两个日志包含了 index 和 term 完全相同的 entry，那从这个 index 往前的那些 entry也都是完全相同的。</li><li><strong>Leader Completeness</strong>：如果一个 entry 在某个 term 被提交，那它将出现在所有 term 更大的 Leaders 的 Log 中。</li><li><strong>State Machine Safety</strong>：如果一个节点apply 了一个Log entry到复制状态机，其他节点不会在同一个index上apply一个不同的entry。</li></ol><h2 id=32-选举>3.2 选举</h2><h3 id=321-选举过程>3.2.1 选举过程</h3><p>上文提到过Leader会定期向Follower发送心跳信息（空的 AppendEntries RPC），如果在一段时间（election timeout）内，Follower即没有收到来自Leader的AppendEntries消息，也没有收到来自 Candidate的 RequestVote消息，那么会超时，变成Candidate发起新一轮选举：</p><ol><li>Follower 增加自己的任期编号，并转换到 Candidate状态。</li><li>该节点给自己投票，重置election timer，同时给其他节点发RequestVoteRPC，请求投票。</li><li>这个节点会一直处于candidate状态，直到：<ol><li><strong>赢得选举（获得大多数节点的投票），成为 Leader</strong>：每个节点在每任期只能投一次票，采取先到先得的方式。如果一个 Candidate成为 Leader后会发送心跳消息通知其他节点，防止其他节点超时，发生新的选举。</li><li><strong>另一个节点成为Leader，该节点变成Follower</strong>：在等待其他的人的投票时，一个 Candidate可能收到来自其他声称是 Leader的AppendEntries RPC，如果这个 Leader的任期编号（包含在RPC消息中）：<ol><li>大于等于这个Candidate的任期，那就承认该节点为Leader，转换为Follower状态。</li><li>小于这个Candidate的任期，拒绝这个RPC消息，继续保持在Candidate 状态。</li></ol></li><li><strong>一段时间后没有节点赢得选举</strong>：如果很多 Follower同时转换为 Candidate，那么投票可能会被分散导致没有人拿到大多数选票（split vote）。当这种情况发生时，Candidate会再次超时，然后开启新一轮的选举（增加任期编号并发送新一轮的RequestVote RPC）。</li></ol></li></ol><h3 id=322-随机选举超时>3.2.2 随机选举超时</h3><p>在上面的情况c中，发生了投票分裂（split vote）的问题，如果投票分裂非常频繁的发生，会导致迟迟无法选出一个Leader，从而影响集群的可用性。</p><p>Raft 使用<strong>随机选举超时机制（election timeout）</strong> 来确保投票分裂很少发生且发生之后能很快恢复正常。</p><ul><li>在Follower状态中，从一些<strong>固定时长（例如 150-300ms）中随机选择一个选举超时时间</strong>，这使得节点的超时时间比较分散，使得在大部分情况下同一时刻最多只有一个节点会超时；。这个超时的节点会在其他节点超时之前赢得选举。</li><li>在Candidate状态中，Candidate 在每一轮选举开始时，会随机重置它的 election timeout，等到 timeout 之后再开始发起新一轮选举，减少了新一轮选举也发生投票分裂的可能性。</li></ul><h2 id=33-日志复制>3.3 日志复制</h2><p>当一个节点成为 Leader后，就开始处理客户端的请求。每一个客户端的请求都包含一个在复制状态机中执行的命令（command）。以下是日志复制的流程：</p><ol><li>Leader将创建一个包含这个command的新 Log entry，追加到Log中去，同时发送AppendEntries RPCs给所有节点复制这个entry。</li><li>当entry成功复制后，Leader状态机执行这个command，并返回结果给client。</li><li>如果Follower crash或因为网络原因丢包，Leader会一直重试直到所有Follower都保存所有的Log entries。</li></ol><h3 id=331-log组织结构>3.3.1 <strong>Log组织结构</strong></h3><p>如下图所示，Log由 Log entry组成，每个entry都有一个按顺序编号的索引。每个entry包含了：</p><ol><li>该entry的任期编号</li><li>具体的命令</li></ol><p><img src=/img/220505Raft/Untitled%203.png alt=Untitled></p><h3 id=332-提交committed>3.3.2 <strong>提交（committed）</strong></h3><p>当一个 Log entry在 Leader的状态机中被执行，就可以说这个entry被提交了（committed）。Raft保证提交过的entry的持久性，即已经提交的entry最终在所有节点上都会被执行。</p><p>Leader会持续更新最大的 committed index，并把这个值放在 AppendEntries RPC中，通知其他节点。当 Follower知道了一个 Log entry已经提交，那么就会在本地的状态机也执行这个entry。</p><p>值得注意的是：</p><ul><li><strong>Leader需要将一个 entry成功复制到大多数节点后，才可以提交这个 entry。</strong></li><li>当 Leader提交一个 entry时，也间接提交了 Leader Log 中的所有前面的 entry，包括那些之前由其他 Leader 创建的 entry。</li></ul><h3 id=333-log的一致性>3.3.3 Log的一致性</h3><p>在上文3.1.6 中提到的 Log Mathching特性保证了Raft各个节点中的一致性：如果两个日志包含了 index 和 term 完全相同的 entry，那从这个 index 往前的那些 entry也都是完全相同的。</p><p>Log Matching Property由以下几点保证：</p><ol><li>如果在不同的节点的 Log中的两个entry拥有同样的index和term，则其中储存的command一定是一样的。因为 Leader对于一个任期内的index，最多创建一个entry，并且永远不改变它的位置。</li><li>如果在不同的节点的 Log中的两个entry包含同样的index和term，那么从该index前的Log都相同。这条特性被appendentries RPC中的一致性检查所保证：<ul><li>Appendentries RPC 请求中，Leader 会附带 Log 中新entry的<strong>前</strong>一个 entry 的 index 和 term 信息。</li><li>如果 Follower的Log 中相同的 index 位置没有 entry，或者有 entry 但 term 不同，Follower 就会拒绝新的 entry。</li></ul></li></ol><h3 id=334--appendentries一致性检查>3.3.4 AppendEntries一致性检查</h3><p>正常情况下，Leader 和 Follower 的 Log 能保持一致。然而，在某些情况下则会出现Log不一致的情况，例如 Leader 还未将其 Log 中的 entry 都复制到其他节点就crash。 例如下图，展示了一些Log不一致的情况（每个方格中是term）：</p><p><img src=/img/220505Raft/Untitled%204.png alt=Untitled></p><ul><li>a-b：entry丢失</li><li>c-d：额外的未提交的entry</li><li>e-f：以上两种情况发生</li></ul><p>从 term 2 开始节点 F成为 Leader，然后向自己的 Log 添加了一些 entry（紫色的term2的entry），但还没来得及提交就崩溃了；然后重启后迅速又成为 term 3 期间的 Leader，然后又加了一些 entry （橙色term3）到自己的 Log，在提交term 2和3的entry之前，又崩溃了；随后持续崩溃了几个 term。</p><p>对于以上出现的不一致性情况，在Raft中，Leader通过强制Follower复制自己的Log来解决不一致的问题，Follower中所有与Leader冲突的Log都会被覆盖，这个过程发生在 <strong>AppendEntries RPC 中的一致性检查</strong>环节：</p><ol><li>找到 Leader 和 Follower 的最后一个共同的 entry。</li><li>将 Follower Log 中从这个 entry 开始往后的 entry 全部删掉。</li><li>将 Leader Log 中从这个entry开始往后的所有 entry 同步给 Follower。</li></ol><p>有了AppendEntries一致性检查的机制，新 Leader 被选出来之后无需执行任何特殊操作来保证 Log 一致性。 它只需要执行正常操作，Logs 会通过 AppendEntries RPC 一致性检查来保持一致。 同时Leader 只会对其他节点中的Log进行更正，永远不会覆盖或删除自己 Log 中的记录。</p><h2 id=34-安全性>3.4 安全性</h2><p>上面的机制并不能保证每个状态机都以相同的顺序执行完全相同的命令。例如，一个 Follower 挂了，故障期间，Leader 提交了几个 Log entry，这些entry并没有同步到Follower上，然后Leader也挂了，Follower恢复之后被选为了新 Leader，并用新的entry 覆盖了之前的entry，导致不同的状态机可能会执行不同的命令。</p><p>在Raft中，存在一些限制确保了任何任期内的 Leader 都包含了前面所有任期提交的 Log entry。</p><h3 id=341-选举限制>3.4.1 选举限制</h3><p>Raft通过投票的过程来确保<strong>不包含所有已提交 Log entry的 Candidate不能赢得选举</strong>：在RequestVote RPC中包含了Candidate Log的信息，如果投票者的Log比Candidate 的Log更新（通过比较最后一个entry的term和index），则会拒绝投票。</p><p>所以，Candidate的 Log至少是和大部分节点已提交的 Log相同。</p><h3 id=342-提交之前任期的entry>3.4.2 提交之前任期的entry</h3><p>Raft不会依据副本数量过半这一规则来提交<strong>之前任期的 Log entry</strong>，只会依据副本数量过半提交当前 Leader 任期的 Log entry。因为Log Matching原则，一旦一个当前任期的entry被提交了，所有之前的Log entries将会被间接提交。</p><p>下面这个例子解释了为什么 Leader不能commit 旧的term的原因：</p><p><img src=/img/220505Raft/Untitled%205.png alt=Untitled></p><ul><li>(a)：S1 是 Leader，并将<code>Index=2</code>的entry 复制到了 S2；</li><li>(b)：S1 崩溃了，S5 接受了S3、S4和它自己的投票被选为新 Leader，任期变为3；然后 S5 在 <code>Index=2</code> 的位置接受了一个不同的 entry；</li><li>(c)：S5 崩溃了；S1 重启并被选为了 Leader，任期变为4； <code>Term=2, Index=2</code> 的entry被同步到了S2和S3上，但并未提交。</li></ul><p>在情况 c的基础上，分两种情况：</p><ul><li>(d)：S1 崩溃了，S5 被选为Leader，并用<code>Term=3</code>的entry覆盖S1、S2、S3中<code>Term=2 & 4entry</code>（因为未提交）。</li><li>(e)：如果S1在崩溃之前将当前任期的entry复制到大多数节上，那么S5将不会被选为Leader。<code>Term=4，Index=3</code>的entry最终也会被新的Leader提交，所有之前的记录也会被提交。</li></ul><h2 id=35-follower和candidate-的崩溃>3.5 Follower和Candidate 的崩溃</h2><p>如果一个 Follower 或 Candidate 崩溃了，那后面来的 RequestVote 和 AppendEntries 请求都会失败。Raft 处理这种问题的方式是<strong>无限重试</strong>，如果这个节点恢复了，这个 RPC 请求就会成功完成。</p><p>如果一个节点在完成了 RPC 之后，响应之前崩溃了，那它会在重启之后收到完全相同的 RPC 。<strong>Raft RPC 是幂等的</strong>，所以多次收到相同的RPC不会产生问题。</p><p>例如，如果一个 Follower 收到了一个 AppendEntries RPC请求，而它的 Log 中已经包含了这个entry，那它会忽略这个请求。</p><h2 id=36-时间和可用性>3.6 时间和可用性</h2><p>Raft的一个要求是安全性不能依赖时序：系统不能因为一些事件发生的速度快慢而产生错误的结果。然而某些方面是不可避免地依赖时序的，比如系统的可用性（系统及时对客户端做出响应）。</p><p>Leader选举过程则更依赖于时序，需要满足以下时间要求：</p><p>$$broadcastTime≪electionTimeout≪MTBF$$</p><ul><li><strong>broadcastTime</strong>：一个节点发送RPC给每一个节点并获得响应的平均时间。</li><li><strong>electionTimeout</strong>：选举超时时间。</li><li><strong>MTBF</strong>：单个节点的平均故障时间。</li></ul><ol><li>broadcastTime要比electionTimeout低一个数量级，以便 Leader 才能可靠地发送心跳消息给 Follower以防止它们发起新的选举。 鉴于到选举超时是随机的，这也使得投票分裂不太可能发生。</li><li>electionTimeout应该比 MTBF 低几个数量级。 当 Leader 崩溃后，系统大致在选举超时的时间段不可用。</li><li>broadcastTime 和 MTBF 都是取决于底层系统，一般来说 electionTimeout 是必须要设置的。<ul><li>Raft 一般要求接收方将请求持久化到稳定存储中，根据不同的存储技术，broadcastTime 可能需要 0.5ms ~ 20ms。</li><li>electionTimeout 通常选择 10ms ~ 500ms。</li><li>通常节点的MTBF是几个月或更长时间。</li></ul></li></ol><h1 id=4-成员变更>4. 成员变更</h1><p>在讨论之前的机制时，默认了集群中的节点个数都是固定的。在Raft中，为了避免集群整个下线或手动操作导致错误，采用了自动化配置变更并将其加入到共识算法中。</p><h2 id=41-增删节点可能导致集群分裂>4.1 增删节点可能导致集群分裂</h2><p>在配置变更过渡期间，必须避免在同一时间同一任期有两个 Leader当选的情况。然而，任直接从旧配置切换到新配置的方法都是不安全的，不可能一次性地切换所有节点的配置，所以集群在过渡期间有可能分裂成两个独立的大多数群体。</p><p>如下图所示，节点数量从 3 个增加到 5 个，在箭头指向的时间点，集群分裂成了两个大多数：一个是还在采用旧配置的 Server 1 & 2，另一个是采用了新配置的 Server 3 & 4 & 5，导致在同一个任期中，有两个不同的 Leader可以被选出来：</p><p><img src=/img/220505Raft/Untitled%206.png alt=Untitled></p><h2 id=42-两阶段提交>4.2 两阶段提交</h2><p>为了保证安全性，在配置变更时，必须使用<strong>两段式设计（two-phase approach）</strong>，在Raft中：</p><ol><li>首先，系统会切换到一个叫做<strong>联合共识（joint consenusus）</strong> 的事务性配置。</li><li>一旦联合共识被提交，那么系统就切换到新配置。</li></ol><p><strong>联合共识结合了老的和新的配置</strong>：</p><ul><li>Log entries 都会被复制到在两种配置中的所有节点。</li><li>两种配置中的任何节点都可能会成为 Leader。</li><li>选举或Log entry提交都需要两种配置中的大多数节点同意。</li></ul><p>联合共识使得每个节点可以在不同的时刻转换配置，而不会影响安全性。同时，联合共识还让集群在配置变更时还可以接收客户端的请求。集群的配置信息储存在特殊的Log entry中，也会被复制和分发。</p><p>如下图所示，虚线代表还未提交的configuration entry，实线代表已经提交的configuration entry。Leader首先创建了一个 $C_{old,new}$ configuration entry并在 $C_{old,new}$ (大多数的 $C_{old}$ 和 $C_{new}$ ）中提交。然后再创建 $C_{new}$ configuration entry，并在 $C_{new}$ 中提交，确保了在同一时刻内没有 $C_{new}$ 和 $C_{old}$ 两个大多数群体分别做决定。</p><p><img src=/img/220505Raft/Untitled%207.png alt=Untitled></p><ul><li>当 Leader 收到一个新的配置变更请求时，会将这个配置作为联合共识存储在一个Log entry中，然后将其同步到其他节点。</li><li>任何一个节点将这个新配置的entry添加到自己的 Log 之后，它将用这个配置来做未来所有的决策，每个节点<strong>永远用它的 Log 中的最新配置，不管这个 entry 是否已提交</strong>。</li><li>如果 Leader 崩溃了，取决于获胜的那个 candidate 是否收到了 $C_{old,new}$，新的 Leader可能会在 $C_{old}$ 或 $C_{old,new}$ 两种状态。但不管哪种情况下，此时（这个时间段内）$C_{new}$ 都无法做出单边决策。</li><li>$C_{old,new}$ 提交之后，除非有其他节点的同意，否则 $C_{old}$ 或 $C_{new}$ 都无法做出决策，并且 Leader Completeness Property 确保了只有那些有 $C_{old,new}$ entry 的节点才能被选为 Leader。在 $C_{old,new}$ 被提交后，Leader 可以安全地创建一个 configuration entry 来描述 $C_{new}$ 并将其同步到集群其他节点。新配置在 $C_{new}$ 的状态下被提交后，旧配置就与集群无关了，那些没有在新配置中的节点就都可以关掉了。</li></ul><h2 id=43-引入新配置的一些问题>4.3 引入新配置的一些问题</h2><ol><li><p>Q：当有新的节点加入集群时，可能没有储存任何 Log entry，如果在这种状态加直接加入集群，<strong>可能会花一段时间赶上 Leader的进度，从而导致无法正常提交 Log entry</strong>。</p><p>A：针对这个问题，Raft在成员变更前加入了一个新的阶段 — 新的节点首先以<strong>非投票者</strong>（Leader会将Log 复制到该节点，但该节点并不算在投票的大多数内）的方式加入集群，一旦该节点与其他节点拥有了一样多的 Log，那么变更就会继续进行。</p></li><li><p>Q：<strong>如果当前的 Leader不在新的配置中怎么办？</strong></p><p>A：这种情况下，Leader 在提交了 $C_{new}$ 之后变成 Follower 状态。这意味着在 Leader 提交 $C_{new}$ 期间，Leader 在管理着一个不包括自己的集群，它可以继续同步 Log entry 给其他节点，但本身却不被算作大多数。 Leader的切换发生在 $C_{new}$ 提交之后，因为这是新配置能独立工作的最早时刻，在这之前，有可能只有 $C_{old}$ 中的某个节点才能被选为 Leader。</p></li><li><p>Q：对于一些在 $C_{new}$ 中被移除的节点，它们不会收到来自 Leader 的心跳，因此会 timeout 然后开始新的选举，它们会带着一个更大的 Term 发起 RequestVote RPC 请求，这会使得当前 Leader 回退到 Follower 。最终虽然会选出一个新 Leader，但这些<strong>被移除的节点会不断地timeout 然后发起新一轮选举，新的 Leader 会再次被变成 Follower，导致可用性很差</strong>。</p><p>A：避免这个问题，节点认为当前已经有一个Leader 的情况下，会忽略 RequestVote RPC。具体的，如果一个节点还没有到最小超时时间就收到了一条 RequestVote RPC，它会忽略这个消息（不会更新 Term 或投票）。这个机制不会影响正常选举，因为每个节点在开始一轮选举之前，会等待至少一个最小超时时间，<strong>只要 Leader 能向集群其他节点正常发送心跳，就不会被更大的Term所影响</strong>。</p></li></ol><h1 id=5-日志压缩>5. 日志压缩</h1><h2 id=51-snapshot>5.1 Snapshot</h2><p>Raft 的 Log 会随着处理客户端请求而不断增大，但在实际系统中，有一个最大的范围。如果占用的存储空间越来越大，replay 时间也越来越长，最终将引发可用性故障。</p><p>Snapshot快照是最简单的压缩方法。在这种方式中，<strong>会对当前的整个日志做一次快照，将其写到持久存储上，然后将已经做过快照的日志全部清空</strong>。每一个节点都可以独立的生成快照，替换已经提交过的Log entry。在快照中也保存了一小部分的元数据（metadata），用来给快照之后的第一个Log entry在接收AppendEntries RPC一致性检查时提供参照。</p><p>快照中包含节点的当前状态，最后一个Log entry的Term和Index。为了配置变更的功能，在快照中也包含了最新的配置。一旦一个节点成功生成了一个快照，它就可以删除这个快照cover的所有Log entries，包括前面的生成的快照。</p><p><img src=/img/220505Raft/Untitled%208.png alt=Untitled></p><h2 id=52-leader向-follower发送快照>5.2 Leader向 Follower发送快照</h2><p>在一些情况下，比如有一个非常慢的 Follower或者一个节点刚加入集群，导致Log entries与Leader落后的非常多，那么 Leader会选择通过 InstallSnapshot RPC发送快照给节点。</p><p><strong>当一个 Follower收到来自 Leader的 InstallSnapshot RPC时</strong>：</p><ol><li>如果快照包含这个 Follower中没有的信息，那么Follower就丢弃全部 Log，由快照取代.</li><li>如果相反，Follower收到一个快照包含了之前的日志（由于重传或错误），那么快照所覆盖的日志会被删除，但快照之后的Log entry仍然是有效，必须保留。</li></ol><p>尽管快照的方式违背了Raft的强领导者原则（因为 Follower可以不经过 Leader的同意而生成快照），但在生成快照时的数据已经达成了共识且不会造成冲突，所以是可以接受的。数据还是从Leader单向向 Follower流动的。</p><p>只有Leader向Follower发送快照，而不由Follower自己生成的缺点：</p><ol><li>每个 Follower在本地已经有了生成快照的数据，Lader向 Follower发送快照不仅会浪费网络资源，也没有 Follower在本地生成的效率高。</li><li>Leader的实现会更麻烦，因为 Leader不仅要向其他节点复制 Log entries，同时还要发送快照。</li></ol><h2 id=53-影响生成快照效率的因素>5.3 影响生成快照效率的因素</h2><ol><li><strong>节点必须决定何时生成快照</strong>：如果太频繁，那会影响磁盘的读写和浪费能源；如果太不频繁，那会增大存储用尽的风险，也会增加重启后replay Log的时间。一个简单的策略是当 Log到达一个固定长度时就生成快照。如果这个值比预计的快照大小大很多，那么snap的磁盘带宽就会少。</li><li><strong>生成快照的过程中会花费一定的时间，并且不能因为生成快照而影响正常的操作</strong>：通过copy-on-write，新的 Log可以在不影响快照生成的情况下接收。例如，复制状态机可以设计成直接支持copy-on-write，或者一些系统级别的copy-on-write可以用来生成一个状态机的in-memoory snapshot。</li></ol><h1 id=6-总结><strong>6. 总结</strong></h1><p>Raft在设计上，将系统分别拆分为 Leader election、Log replication、Safety等几个模块，并减少状态数量，采用了强领导者模型，使整个算法更好理解和实现。</p><p>在 <a href=https://pdos.csail.mit.edu/6.824/labs/lab-raft.html>MIT 6.824 Lab 2</a>中，将整个实验分为选举、日志复制、持久化和日志压缩四个模块，通过实现这四个模块也会让你对Raft有更深刻的理解。</p><p>另外，在 <a href=http://raft.github.io/>raft.github.io</a> 上面，有一个Raft Visualization的部分，可以手动模拟在集群中发生的各种状况，能更好的帮助你理解Raft。</p><h3 id=reference>Reference</h3><ol><li>In Search of an Understandable Consensus Algorithm <a href=https://www.usenix.org/conference/atc14/technical-sessions/presentation/ongaro>https://www.usenix.org/conference/atc14/technical-sessions/presentation/ongaro</a></li><li>[译] [论文] Raft 共识算法（及 etcd/raft 源码解析）（USENIX, 2014） <a href=https://arthurchiao.art/blog/raft-paper-zh>https://arthurchiao.art/blog/raft-paper-zh</a></li></ol><hr><ul class=pager><li class=previous><a href=/tech/MIT-6.824-Lab-1/ data-toggle=tooltip data-placement=top title="MIT 6.824 Lab 1">&larr;
Previous Post</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/.net title=.net>.net</a>
<a href=/tags/asp.net title=asp.net>asp.net</a>
<a href=/tags/distributed-system title=distributed-system>distributed-system</a>
<a href=/tags/go title=go>go</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href></a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:dukesaika@gmail.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/dukezys><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://www.linkedin.com/in/yinsong-zhao-6957901a9><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 2022 Ganymede<br>Powered by <a href=https://gohugo.io/>Hugo</a>,
Theme originated from
<a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a>
<span id=busuanzi_container_site_pv>本站总访问量<span id=busuanzi_value_site_pv></span>次</span></p></div></div></div></footer><script>function loadAsync(i,t){var n=document,s="script",e=n.createElement(s),o=n.getElementsByTagName(s)[0];e.src=i,t&&e.addEventListener("load",function(e){t(null,e)},!1),o.parentNode.insertBefore(e,o)}</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(''),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></body></html>